{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Cherry___healthy',\n",
       " 'Cherry___Powdery_mildew',\n",
       " 'Corn___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn___Common_rust',\n",
       " 'Corn___healthy',\n",
       " 'Corn___Northern_Leaf_Blight',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___healthy',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___healthy',\n",
       " 'Potato___Late_blight',\n",
       " 'Strawberry___healthy',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___healthy',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "dataset_dir = \"D:/dataset\"\n",
    "classes_list = os.listdir(dataset_dir)\n",
    "\n",
    "base_dir = \"D:/splitted\"\n",
    "os.makedirs(base_dir,exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "os.makedirs(train_dir,exist_ok=True)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "os.makedirs(validation_dir,exist_ok=True)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "os.makedirs(test_dir,exist_ok=True)\n",
    "\n",
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes_list:\n",
    "    os.makedirs(os.path.join(train_dir,cls),exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir,cls),exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir,cls),exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size(Apple___Apple_scab): 378\n",
      "validation size(Apple___Apple_scab): 126\n",
      "test size(Apple___Apple_scab): 126\n",
      "Train size(Apple___Black_rot): 372\n",
      "validation size(Apple___Black_rot): 124\n",
      "test size(Apple___Black_rot): 125\n",
      "Train size(Apple___Cedar_apple_rust): 165\n",
      "validation size(Apple___Cedar_apple_rust): 55\n",
      "test size(Apple___Cedar_apple_rust): 55\n",
      "Train size(Apple___healthy): 987\n",
      "validation size(Apple___healthy): 329\n",
      "test size(Apple___healthy): 329\n",
      "Train size(Cherry___healthy): 512\n",
      "validation size(Cherry___healthy): 170\n",
      "test size(Cherry___healthy): 172\n",
      "Train size(Cherry___Powdery_mildew): 631\n",
      "validation size(Cherry___Powdery_mildew): 210\n",
      "test size(Cherry___Powdery_mildew): 211\n",
      "Train size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 307\n",
      "validation size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 102\n",
      "test size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 104\n",
      "Train size(Corn___Common_rust): 715\n",
      "validation size(Corn___Common_rust): 238\n",
      "test size(Corn___Common_rust): 239\n",
      "Train size(Corn___healthy): 697\n",
      "validation size(Corn___healthy): 232\n",
      "test size(Corn___healthy): 233\n",
      "Train size(Corn___Northern_Leaf_Blight): 591\n",
      "validation size(Corn___Northern_Leaf_Blight): 197\n",
      "test size(Corn___Northern_Leaf_Blight): 197\n",
      "Train size(Grape___Black_rot): 708\n",
      "validation size(Grape___Black_rot): 236\n",
      "test size(Grape___Black_rot): 236\n",
      "Train size(Grape___Esca_(Black_Measles)): 829\n",
      "validation size(Grape___Esca_(Black_Measles)): 276\n",
      "test size(Grape___Esca_(Black_Measles)): 278\n",
      "Train size(Grape___healthy): 253\n",
      "validation size(Grape___healthy): 84\n",
      "test size(Grape___healthy): 86\n",
      "Train size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 645\n",
      "validation size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 215\n",
      "test size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 216\n",
      "Train size(Peach___Bacterial_spot): 1378\n",
      "validation size(Peach___Bacterial_spot): 459\n",
      "test size(Peach___Bacterial_spot): 460\n",
      "Train size(Peach___healthy): 216\n",
      "validation size(Peach___healthy): 72\n",
      "test size(Peach___healthy): 72\n",
      "Train size(Pepper,_bell___Bacterial_spot): 598\n",
      "validation size(Pepper,_bell___Bacterial_spot): 199\n",
      "test size(Pepper,_bell___Bacterial_spot): 200\n",
      "Train size(Pepper,_bell___healthy): 886\n",
      "validation size(Pepper,_bell___healthy): 295\n",
      "test size(Pepper,_bell___healthy): 297\n",
      "Train size(Potato___Early_blight): 600\n",
      "validation size(Potato___Early_blight): 200\n",
      "test size(Potato___Early_blight): 200\n",
      "Train size(Potato___healthy): 91\n",
      "validation size(Potato___healthy): 30\n",
      "test size(Potato___healthy): 31\n",
      "Train size(Potato___Late_blight): 600\n",
      "validation size(Potato___Late_blight): 200\n",
      "test size(Potato___Late_blight): 200\n",
      "Train size(Strawberry___healthy): 273\n",
      "validation size(Strawberry___healthy): 91\n",
      "test size(Strawberry___healthy): 92\n",
      "Train size(Strawberry___Leaf_scorch): 665\n",
      "validation size(Strawberry___Leaf_scorch): 221\n",
      "test size(Strawberry___Leaf_scorch): 223\n",
      "Train size(Tomato___Bacterial_spot): 1276\n",
      "validation size(Tomato___Bacterial_spot): 425\n",
      "test size(Tomato___Bacterial_spot): 426\n",
      "Train size(Tomato___Early_blight): 600\n",
      "validation size(Tomato___Early_blight): 200\n",
      "test size(Tomato___Early_blight): 200\n",
      "Train size(Tomato___healthy): 954\n",
      "validation size(Tomato___healthy): 318\n",
      "test size(Tomato___healthy): 319\n",
      "Train size(Tomato___Late_blight): 1145\n",
      "validation size(Tomato___Late_blight): 381\n",
      "test size(Tomato___Late_blight): 383\n",
      "Train size(Tomato___Leaf_Mold): 571\n",
      "validation size(Tomato___Leaf_Mold): 190\n",
      "test size(Tomato___Leaf_Mold): 191\n",
      "Train size(Tomato___Septoria_leaf_spot): 1062\n",
      "validation size(Tomato___Septoria_leaf_spot): 354\n",
      "test size(Tomato___Septoria_leaf_spot): 355\n",
      "Train size(Tomato___Spider_mites Two-spotted_spider_mite): 1005\n",
      "validation size(Tomato___Spider_mites Two-spotted_spider_mite): 335\n",
      "test size(Tomato___Spider_mites Two-spotted_spider_mite): 336\n",
      "Train size(Tomato___Target_Spot): 842\n",
      "validation size(Tomato___Target_Spot): 280\n",
      "test size(Tomato___Target_Spot): 282\n",
      "Train size(Tomato___Tomato_mosaic_virus): 223\n",
      "validation size(Tomato___Tomato_mosaic_virus): 74\n",
      "test size(Tomato___Tomato_mosaic_virus): 76\n",
      "Train size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 3214\n",
      "validation size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 1071\n",
      "test size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 1072\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "\n",
    "for cls in classes_list:\n",
    "    path = os.path.join(dataset_dir,cls)\n",
    "    fnames = os.listdir(path)\n",
    "\n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "\n",
    "\n",
    "    train_fnames = fnames[:train_size]\n",
    "    print(f\"Train size({cls}): {len(train_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(train_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "    \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print(f\"validation size({cls}): {len(validation_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(validation_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "\n",
    "    test_fnames = fnames[(validation_size + train_size):]\n",
    "    print(f\"test size({cls}): {len(test_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(test_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.0.1 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_cpp_backtrace' from 'torch._C' (c:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\_C.cp310-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m\n\u001b[0;32m      7\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageFolder\n\u001b[0;32m     12\u001b[0m transform_base \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize((\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m)), transforms\u001b[39m.\u001b[39mToTensor()])\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodulefinder\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39malexnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdensenet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mefficientnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstochastic_depth\u001b[39;00m \u001b[39mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_presets\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\ops\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_register_onnx_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m _register_custom_op\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mboxes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     batched_nms,\n\u001b[0;32m      4\u001b[0m     box_area,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     remove_small_boxes,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mciou_loss\u001b[39;00m \u001b[39mimport\u001b[39;00m complete_box_iou_loss\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torchvision\\ops\\_register_onnx_ops.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m symbolic_opset11 \u001b[39mas\u001b[39;00m opset11\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msymbolic_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_args\n\u001b[0;32m      8\u001b[0m _ONNX_OPSET_VERSION_11 \u001b[39m=\u001b[39m \u001b[39m11\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\onnx\\symbolic_opset11.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _onnx \u001b[39mas\u001b[39;00m _C_onnx\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _type_utils,\n\u001b[0;32m     14\u001b[0m     errors,\n\u001b[0;32m     15\u001b[0m     symbolic_helper,\n\u001b[0;32m     16\u001b[0m     symbolic_opset10 \u001b[39mas\u001b[39;00m opset10,\n\u001b[0;32m     17\u001b[0m     symbolic_opset9 \u001b[39mas\u001b[39;00m opset9,\n\u001b[0;32m     18\u001b[0m     utils,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_globals\u001b[39;00m \u001b[39mimport\u001b[39;00m GLOBALS\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _beartype, jit_utils, registration\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\onnx\\_type_utils.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _onnx \u001b[39mas\u001b[39;00m _C_onnx\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m errors\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _beartype\n\u001b[0;32m     14\u001b[0m \u001b[39mif\u001b[39;00m typing\u001b[39m.\u001b[39mTYPE_CHECKING:\n\u001b[0;32m     15\u001b[0m     \u001b[39m# Hack to help mypy to recognize torch._C.Value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\onnx\\errors.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m _constants\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m diagnostics\n\u001b[0;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnnxExporterError\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnnxExporterWarning\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSymbolicValueError\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mOnnxExporterWarning\u001b[39;00m(\u001b[39mUserWarning\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_diagnostic\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     create_export_diagnostic_context,\n\u001b[0;32m      3\u001b[0m     diagnose,\n\u001b[0;32m      4\u001b[0m     engine,\n\u001b[0;32m      5\u001b[0m     export_context,\n\u001b[0;32m      6\u001b[0m     ExportDiagnostic,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_rules\u001b[39;00m \u001b[39mimport\u001b[39;00m rules\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39minfra\u001b[39;00m \u001b[39mimport\u001b[39;00m levels\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\_diagnostic.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiagnostics\u001b[39;00m \u001b[39mimport\u001b[39;00m infra\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_backtrace\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cpp_call_stack\u001b[39m(frames_to_skip: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, frames_to_log: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m infra\u001b[39m.\u001b[39mStack:\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\"\"Returns the current C++ call stack.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39m    This function utilizes `torch.utils.cpp_backtrace` to get the current C++ call stack.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_backtrace.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _get_cpp_backtrace\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cpp_backtrace\u001b[39m(frames_to_skip\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maximum_number_of_frames\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m    Returns a string containing the C++ stack trace of the current thread.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m        frames_to_skip (int): the number of frames to skip from the top of the stack\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m        maximum_number_of_frames (int): the maximum number of frames to return\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_get_cpp_backtrace' from 'torch._C' (c:\\Users\\ben81\\anaconda3\\lib\\site-packages\\torch\\_C.cp310-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(train_dir, transform=transform_base)\n",
    "validation_dataset = ImageFolder(validation_dir, transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "vallidation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

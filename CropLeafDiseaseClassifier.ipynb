{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작물 잎 사진으로 질병 분류하기 - 출처:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Cherry___healthy',\n",
       " 'Cherry___Powdery_mildew',\n",
       " 'Corn___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn___Common_rust',\n",
       " 'Corn___healthy',\n",
       " 'Corn___Northern_Leaf_Blight',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___healthy',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___healthy',\n",
       " 'Potato___Late_blight',\n",
       " 'Strawberry___healthy',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___healthy',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "dataset_dir = \"D:/dataset\"\n",
    "classes_list = os.listdir(dataset_dir)\n",
    "\n",
    "base_dir = \"D:/splitted\"\n",
    "os.makedirs(base_dir,exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "os.makedirs(train_dir,exist_ok=True)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "os.makedirs(validation_dir,exist_ok=True)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "os.makedirs(test_dir,exist_ok=True)\n",
    "\n",
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes_list:\n",
    "    os.makedirs(os.path.join(train_dir,cls),exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir,cls),exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir,cls),exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size(Apple___Apple_scab): 378\n",
      "validation size(Apple___Apple_scab): 126\n",
      "test size(Apple___Apple_scab): 126\n",
      "Train size(Apple___Black_rot): 372\n",
      "validation size(Apple___Black_rot): 124\n",
      "test size(Apple___Black_rot): 125\n",
      "Train size(Apple___Cedar_apple_rust): 165\n",
      "validation size(Apple___Cedar_apple_rust): 55\n",
      "test size(Apple___Cedar_apple_rust): 55\n",
      "Train size(Apple___healthy): 987\n",
      "validation size(Apple___healthy): 329\n",
      "test size(Apple___healthy): 329\n",
      "Train size(Cherry___healthy): 512\n",
      "validation size(Cherry___healthy): 170\n",
      "test size(Cherry___healthy): 172\n",
      "Train size(Cherry___Powdery_mildew): 631\n",
      "validation size(Cherry___Powdery_mildew): 210\n",
      "test size(Cherry___Powdery_mildew): 211\n",
      "Train size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 307\n",
      "validation size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 102\n",
      "test size(Corn___Cercospora_leaf_spot Gray_leaf_spot): 104\n",
      "Train size(Corn___Common_rust): 715\n",
      "validation size(Corn___Common_rust): 238\n",
      "test size(Corn___Common_rust): 239\n",
      "Train size(Corn___healthy): 697\n",
      "validation size(Corn___healthy): 232\n",
      "test size(Corn___healthy): 233\n",
      "Train size(Corn___Northern_Leaf_Blight): 591\n",
      "validation size(Corn___Northern_Leaf_Blight): 197\n",
      "test size(Corn___Northern_Leaf_Blight): 197\n",
      "Train size(Grape___Black_rot): 708\n",
      "validation size(Grape___Black_rot): 236\n",
      "test size(Grape___Black_rot): 236\n",
      "Train size(Grape___Esca_(Black_Measles)): 829\n",
      "validation size(Grape___Esca_(Black_Measles)): 276\n",
      "test size(Grape___Esca_(Black_Measles)): 278\n",
      "Train size(Grape___healthy): 253\n",
      "validation size(Grape___healthy): 84\n",
      "test size(Grape___healthy): 86\n",
      "Train size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 645\n",
      "validation size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 215\n",
      "test size(Grape___Leaf_blight_(Isariopsis_Leaf_Spot)): 216\n",
      "Train size(Peach___Bacterial_spot): 1378\n",
      "validation size(Peach___Bacterial_spot): 459\n",
      "test size(Peach___Bacterial_spot): 460\n",
      "Train size(Peach___healthy): 216\n",
      "validation size(Peach___healthy): 72\n",
      "test size(Peach___healthy): 72\n",
      "Train size(Pepper,_bell___Bacterial_spot): 598\n",
      "validation size(Pepper,_bell___Bacterial_spot): 199\n",
      "test size(Pepper,_bell___Bacterial_spot): 200\n",
      "Train size(Pepper,_bell___healthy): 886\n",
      "validation size(Pepper,_bell___healthy): 295\n",
      "test size(Pepper,_bell___healthy): 297\n",
      "Train size(Potato___Early_blight): 600\n",
      "validation size(Potato___Early_blight): 200\n",
      "test size(Potato___Early_blight): 200\n",
      "Train size(Potato___healthy): 91\n",
      "validation size(Potato___healthy): 30\n",
      "test size(Potato___healthy): 31\n",
      "Train size(Potato___Late_blight): 600\n",
      "validation size(Potato___Late_blight): 200\n",
      "test size(Potato___Late_blight): 200\n",
      "Train size(Strawberry___healthy): 273\n",
      "validation size(Strawberry___healthy): 91\n",
      "test size(Strawberry___healthy): 92\n",
      "Train size(Strawberry___Leaf_scorch): 665\n",
      "validation size(Strawberry___Leaf_scorch): 221\n",
      "test size(Strawberry___Leaf_scorch): 223\n",
      "Train size(Tomato___Bacterial_spot): 1276\n",
      "validation size(Tomato___Bacterial_spot): 425\n",
      "test size(Tomato___Bacterial_spot): 426\n",
      "Train size(Tomato___Early_blight): 600\n",
      "validation size(Tomato___Early_blight): 200\n",
      "test size(Tomato___Early_blight): 200\n",
      "Train size(Tomato___healthy): 954\n",
      "validation size(Tomato___healthy): 318\n",
      "test size(Tomato___healthy): 319\n",
      "Train size(Tomato___Late_blight): 1145\n",
      "validation size(Tomato___Late_blight): 381\n",
      "test size(Tomato___Late_blight): 383\n",
      "Train size(Tomato___Leaf_Mold): 571\n",
      "validation size(Tomato___Leaf_Mold): 190\n",
      "test size(Tomato___Leaf_Mold): 191\n",
      "Train size(Tomato___Septoria_leaf_spot): 1062\n",
      "validation size(Tomato___Septoria_leaf_spot): 354\n",
      "test size(Tomato___Septoria_leaf_spot): 355\n",
      "Train size(Tomato___Spider_mites Two-spotted_spider_mite): 1005\n",
      "validation size(Tomato___Spider_mites Two-spotted_spider_mite): 335\n",
      "test size(Tomato___Spider_mites Two-spotted_spider_mite): 336\n",
      "Train size(Tomato___Target_Spot): 842\n",
      "validation size(Tomato___Target_Spot): 280\n",
      "test size(Tomato___Target_Spot): 282\n",
      "Train size(Tomato___Tomato_mosaic_virus): 223\n",
      "validation size(Tomato___Tomato_mosaic_virus): 74\n",
      "test size(Tomato___Tomato_mosaic_virus): 76\n",
      "Train size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 3214\n",
      "validation size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 1071\n",
      "test size(Tomato___Tomato_Yellow_Leaf_Curl_Virus): 1072\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "\n",
    "for cls in classes_list:\n",
    "    path = os.path.join(dataset_dir,cls)\n",
    "    fnames = os.listdir(path)\n",
    "\n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "\n",
    "\n",
    "    train_fnames = fnames[:train_size]\n",
    "    print(f\"Train size({cls}): {len(train_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(train_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "    \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print(f\"validation size({cls}): {len(validation_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(validation_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "\n",
    "    test_fnames = fnames[(validation_size + train_size):]\n",
    "    print(f\"test size({cls}): {len(test_fnames)}\")\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(path,fname)\n",
    "        dst = os.path.join(test_dir,cls,fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ben81\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.0.1 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(train_dir, transform=transform_base)\n",
    "validation_dataset = ImageFolder(validation_dir, transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "vallidation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,32,3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2  = nn.Conv2d(32,64,3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64,64,3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, 33)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x= F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        x = x.view(-1,64*8*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model_base = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()       \n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)      #classification = cross_entropy\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0 \n",
    "\n",
    "    with torch.no_grad():   \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target,reduction='sum').item()\n",
    "            pred = output.max(1,keepdim=True)[1]    \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Train Loss: 1.3815  Train Acc: 57.86%  Val Loss: 1.3815  Val Acc: 57.86%  Time: 4m 14s\n",
      "Epoch: 2  Train Loss: 0.7826  Train Acc: 76.60%  Val Loss: 0.7826  Val Acc: 76.60%  Time: 4m 4s\n",
      "Epoch: 3  Train Loss: 0.5393  Train Acc: 83.58%  Val Loss: 0.5393  Val Acc: 83.58%  Time: 3m 55s\n",
      "Epoch: 4  Train Loss: 0.4539  Train Acc: 85.44%  Val Loss: 0.4539  Val Acc: 85.44%  Time: 4m 1s\n",
      "Epoch: 5  Train Loss: 0.3858  Train Acc: 88.08%  Val Loss: 0.3858  Val Acc: 88.08%  Time: 4m 8s\n",
      "Epoch: 6  Train Loss: 0.3190  Train Acc: 90.05%  Val Loss: 0.3190  Val Acc: 90.05%  Time: 3m 40s\n",
      "Epoch: 7  Train Loss: 0.2680  Train Acc: 91.92%  Val Loss: 0.2680  Val Acc: 91.92%  Time: 3m 52s\n",
      "Epoch: 8  Train Loss: 0.2812  Train Acc: 90.90%  Val Loss: 0.2812  Val Acc: 90.90%  Time: 3m 46s\n",
      "Epoch: 9  Train Loss: 0.2533  Train Acc: 92.19%  Val Loss: 0.2533  Val Acc: 92.19%  Time: 3m 50s\n",
      "Epoch: 10  Train Loss: 0.2139  Train Acc: 93.30%  Val Loss: 0.2139  Val Acc: 93.30%  Time: 4m 0s\n",
      "Epoch: 11  Train Loss: 0.1845  Train Acc: 94.64%  Val Loss: 0.1845  Val Acc: 94.64%  Time: 4m 2s\n",
      "Epoch: 12  Train Loss: 0.1619  Train Acc: 95.42%  Val Loss: 0.1619  Val Acc: 95.42%  Time: 4m 0s\n",
      "Epoch: 13  Train Loss: 0.1499  Train Acc: 95.62%  Val Loss: 0.1499  Val Acc: 95.62%  Time: 3m 58s\n",
      "Epoch: 14  Train Loss: 0.1326  Train Acc: 96.19%  Val Loss: 0.1326  Val Acc: 96.19%  Time: 3m 48s\n",
      "Epoch: 15  Train Loss: 0.1284  Train Acc: 96.25%  Val Loss: 0.1284  Val Acc: 96.25%  Time: 3m 51s\n",
      "Epoch: 16  Train Loss: 0.1236  Train Acc: 96.52%  Val Loss: 0.1236  Val Acc: 96.52%  Time: 4m 17s\n",
      "Epoch: 17  Train Loss: 0.1031  Train Acc: 97.23%  Val Loss: 0.1031  Val Acc: 97.23%  Time: 4m 4s\n",
      "Epoch: 18  Train Loss: 0.1006  Train Acc: 96.98%  Val Loss: 0.1006  Val Acc: 96.98%  Time: 4m 9s\n",
      "Epoch: 19  Train Loss: 0.0916  Train Acc: 97.27%  Val Loss: 0.0916  Val Acc: 97.27%  Time: 4m 5s\n",
      "Epoch: 20  Train Loss: 0.0808  Train Acc: 97.82%  Val Loss: 0.0808  Val Acc: 97.82%  Time: 3m 30s\n",
      "Epoch: 21  Train Loss: 0.0757  Train Acc: 97.84%  Val Loss: 0.0757  Val Acc: 97.84%  Time: 3m 27s\n",
      "Epoch: 22  Train Loss: 0.0691  Train Acc: 98.08%  Val Loss: 0.0691  Val Acc: 98.08%  Time: 3m 30s\n",
      "Epoch: 23  Train Loss: 0.1124  Train Acc: 96.30%  Val Loss: 0.1124  Val Acc: 96.30%  Time: 3m 33s\n",
      "Epoch: 24  Train Loss: 0.0549  Train Acc: 98.53%  Val Loss: 0.0549  Val Acc: 98.53%  Time: 3m 22s\n",
      "Epoch: 25  Train Loss: 0.0775  Train Acc: 97.75%  Val Loss: 0.0775  Val Acc: 97.75%  Time: 3m 36s\n",
      "Epoch: 26  Train Loss: 0.0567  Train Acc: 98.37%  Val Loss: 0.0567  Val Acc: 98.37%  Time: 3m 24s\n",
      "Epoch: 27  Train Loss: 0.0573  Train Acc: 98.44%  Val Loss: 0.0573  Val Acc: 98.44%  Time: 3m 15s\n",
      "Epoch: 28  Train Loss: 0.0467  Train Acc: 98.78%  Val Loss: 0.0467  Val Acc: 98.78%  Time: 3m 16s\n",
      "Epoch: 29  Train Loss: 0.0455  Train Acc: 98.89%  Val Loss: 0.0455  Val Acc: 98.89%  Time: 3m 16s\n",
      "Epoch: 30  Train Loss: 0.0443  Train Acc: 99.01%  Val Loss: 0.0443  Val Acc: 99.01%  Time: 3m 21s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, num_epochs=30):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()\n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader)\n",
    "        val_loss, val_acc = evaluate(model, test_loader)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch: {}  Train Loss: {:.4f}  Train Acc: {:.2f}%  Val Loss: {:.4f}  Val Acc: {:.2f}%  Time: {:.0f}m {:.0f}s'.format(epoch, train_loss, train_acc, val_loss, val_acc, time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_base = train_model(model_base, train_loader, vallidation_loader, optimizer, EPOCHS)\n",
    "torch.save(model_base, 'beseline.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

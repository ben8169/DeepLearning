{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron 수식 : $y = \\sigma(\\displaystyle\\sum_{i=1}^{3} w_{i}x_{i} + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "W = np.array([4, 5, 6])\n",
    "B = 10\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4, 10, 18]), 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul = X * W\n",
    "matmul = np.matmul(X, W)\n",
    "\n",
    "mul, matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Perceptron 연산 : np.matmul() 이용\n",
    "> * s = np.matmul(X, W) + b\n",
    ">> $S=X\\cdot W + b= \\begin{bmatrix}x_{1}&x_{2}&x_{3}\\end{bmatrix}\\begin{bmatrix}w_{1}\\\\w_{2}\\\\w_{3}\\end{bmatrix} + b = x_{1}w_{1} + x_{2}w_{2} + x_{3}w_{3} + b $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### [예제 1] Hypothesis, Cost Function of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input and Labels\n",
    "x_input = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype= np.float32)\n",
    "labels = np.array([3, 5, 7, 9, 11, 13, 15, 17, 19, 21], dtype= np.float32)\n",
    "x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Hypothesis : Linear Equation\n",
    ">### $h(x) = wx + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis : Linear Function\n",
    "def Hypothesis(x):    \n",
    "    return W*x + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Cost Function : Mean Squared Error (MSE)\n",
    ">### $\\sum_{i=1}^{n}(h(x_{i})-y_{i})^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost : Mean Squared Error\n",
    "def Cost():\n",
    "    return np.mean((Hypothesis(x_input) - labels)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Test : Hypothesis, Cost Function of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost(W= 2. B= 2): 1.0\n",
      "cost(W=-2. B=23): 132.0\n",
      "cost(W=-2. B=23): 50.5\n"
     ]
    }
   ],
   "source": [
    "# w,b 값에 따른 Hypothesis, Cost 테스트\n",
    "W, B = 2, 2\n",
    "res_cost = Cost()\n",
    "print(\"cost(W= 2. B= 2): {}\".format(res_cost))\n",
    "W, B = -2, 23\n",
    "res_cost = Cost()\n",
    "print(\"cost(W=-2. B=23): {}\".format(res_cost))\n",
    "W, B =1, 0\n",
    "res_cost = Cost()\n",
    "print(\"cost(W=-2. B=23): {}\".format(res_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_list = np.arange(10)\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost(W= 0. B= 0): 177.0\n",
      "cost(W= 0. B= 1): 154.0\n",
      "cost(W= 0. B= 2): 133.0\n",
      "cost(W= 0. B= 3): 114.0\n",
      "cost(W= 0. B= 4): 97.0\n",
      "cost(W= 0. B= 5): 82.0\n",
      "cost(W= 0. B= 6): 69.0\n",
      "cost(W= 0. B= 7): 58.0\n",
      "cost(W= 0. B= 8): 49.0\n",
      "cost(W= 0. B= 9): 42.0\n",
      "cost(W= 1. B= 0): 50.5\n",
      "cost(W= 1. B= 1): 38.5\n",
      "cost(W= 1. B= 2): 28.5\n",
      "cost(W= 1. B= 3): 20.5\n",
      "cost(W= 1. B= 4): 14.5\n",
      "cost(W= 1. B= 5): 10.5\n",
      "cost(W= 1. B= 6): 8.5\n",
      "cost(W= 1. B= 7): 8.5\n",
      "cost(W= 1. B= 8): 10.5\n",
      "cost(W= 1. B= 9): 14.5\n",
      "cost(W= 2. B= 0): 1.0\n",
      "cost(W= 2. B= 1): 0.0\n",
      "cost(W= 2. B= 2): 1.0\n",
      "cost(W= 2. B= 3): 4.0\n",
      "cost(W= 2. B= 4): 9.0\n",
      "cost(W= 2. B= 5): 16.0\n",
      "cost(W= 2. B= 6): 25.0\n",
      "cost(W= 2. B= 7): 36.0\n",
      "cost(W= 2. B= 8): 49.0\n",
      "cost(W= 2. B= 9): 64.0\n",
      "cost(W= 3. B= 0): 28.5\n",
      "cost(W= 3. B= 1): 38.5\n",
      "cost(W= 3. B= 2): 50.5\n",
      "cost(W= 3. B= 3): 64.5\n",
      "cost(W= 3. B= 4): 80.5\n",
      "cost(W= 3. B= 5): 98.5\n",
      "cost(W= 3. B= 6): 118.5\n",
      "cost(W= 3. B= 7): 140.5\n",
      "cost(W= 3. B= 8): 164.5\n",
      "cost(W= 3. B= 9): 190.5\n",
      "cost(W= 4. B= 0): 133.0\n",
      "cost(W= 4. B= 1): 154.0\n",
      "cost(W= 4. B= 2): 177.0\n",
      "cost(W= 4. B= 3): 202.0\n",
      "cost(W= 4. B= 4): 229.0\n",
      "cost(W= 4. B= 5): 258.0\n",
      "cost(W= 4. B= 6): 289.0\n",
      "cost(W= 4. B= 7): 322.0\n",
      "cost(W= 4. B= 8): 357.0\n",
      "cost(W= 4. B= 9): 394.0\n",
      "cost(W= 5. B= 0): 314.5\n",
      "cost(W= 5. B= 1): 346.5\n",
      "cost(W= 5. B= 2): 380.5\n",
      "cost(W= 5. B= 3): 416.5\n",
      "cost(W= 5. B= 4): 454.5\n",
      "cost(W= 5. B= 5): 494.5\n",
      "cost(W= 5. B= 6): 536.5\n",
      "cost(W= 5. B= 7): 580.5\n",
      "cost(W= 5. B= 8): 626.5\n",
      "cost(W= 5. B= 9): 674.5\n",
      "cost(W= 6. B= 0): 573.0\n",
      "cost(W= 6. B= 1): 616.0\n",
      "cost(W= 6. B= 2): 661.0\n",
      "cost(W= 6. B= 3): 708.0\n",
      "cost(W= 6. B= 4): 757.0\n",
      "cost(W= 6. B= 5): 808.0\n",
      "cost(W= 6. B= 6): 861.0\n",
      "cost(W= 6. B= 7): 916.0\n",
      "cost(W= 6. B= 8): 973.0\n",
      "cost(W= 6. B= 9): 1032.0\n",
      "cost(W= 7. B= 0): 908.5\n",
      "cost(W= 7. B= 1): 962.5\n",
      "cost(W= 7. B= 2): 1018.5\n",
      "cost(W= 7. B= 3): 1076.5\n",
      "cost(W= 7. B= 4): 1136.5\n",
      "cost(W= 7. B= 5): 1198.5\n",
      "cost(W= 7. B= 6): 1262.5\n",
      "cost(W= 7. B= 7): 1328.5\n",
      "cost(W= 7. B= 8): 1396.5\n",
      "cost(W= 7. B= 9): 1466.5\n",
      "cost(W= 8. B= 0): 1321.0\n",
      "cost(W= 8. B= 1): 1386.0\n",
      "cost(W= 8. B= 2): 1453.0\n",
      "cost(W= 8. B= 3): 1522.0\n",
      "cost(W= 8. B= 4): 1593.0\n",
      "cost(W= 8. B= 5): 1666.0\n",
      "cost(W= 8. B= 6): 1741.0\n",
      "cost(W= 8. B= 7): 1818.0\n",
      "cost(W= 8. B= 8): 1897.0\n",
      "cost(W= 8. B= 9): 1978.0\n",
      "cost(W= 9. B= 0): 1810.5\n",
      "cost(W= 9. B= 1): 1886.5\n",
      "cost(W= 9. B= 2): 1964.5\n",
      "cost(W= 9. B= 3): 2044.5\n",
      "cost(W= 9. B= 4): 2126.5\n",
      "cost(W= 9. B= 5): 2210.5\n",
      "cost(W= 9. B= 6): 2296.5\n",
      "cost(W= 9. B= 7): 2384.5\n",
      "cost(W= 9. B= 8): 2474.5\n",
      "cost(W= 9. B= 9): 2566.5\n"
     ]
    }
   ],
   "source": [
    "for W in range(10):\n",
    "    for B in range(10):\n",
    "        res_cost = Cost()\n",
    "        print(f\"cost(W= {W}. B= {B}): {res_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### [예제 2] Gradient Descent of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6845557716179558, -0.09976794339087067)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input and Labels\n",
    "x_input = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype= np.float32)\n",
    "labels = np.array([3, 5, 7, 9, 11, 13, 15, 17, 19, 21], dtype= np.float32)\n",
    "\n",
    "# Weights, Biases\n",
    "W = np.random.normal()\n",
    "B = np.random.normal()\n",
    "W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Hypothesis : Linear Equation\n",
    ">### $h(x) = wx + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis : Linear Function\n",
    "def Hypothesis(x):    \n",
    "    return W*x + B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Cost Function : Mean Squared Error (MSE)\n",
    ">### $\\sum_{i=1}^{n}(h(x_{i})-y_{i})^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost : Mean Squared Error \n",
    "def Cost():\n",
    "    return np.mean((Hypothesis(x_input) - labels)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Gradient\n",
    ">### $\\frac{\\partial}{\\partial w}cost(w, b) = \\frac{1}{m}  \\sum_{i=1}^{m}(x_{i}(x_{i}w+(b-y_{i})))$\n",
    ">### $\\frac{\\partial}{\\partial b}cost(w, b) = \\frac{1}{m}  \\sum_{i=1}^{m}(x_{i}w - y_{i} + b)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#장점 : 속도가 빠르고,정확하다 단점: 진짜로 미분해줘야함\n",
    "# def Gradient(x, y):\n",
    "#     return np.mean(x*(x*W+(B-y))), np.mean((W*x-y+B))\n",
    "\n",
    "def Gradient(x, y):\n",
    "    global W, B\n",
    "    pres_w, pres_b = W, B # W,B backup\n",
    "    delta = 5e-7  #아주 작은 값, lim x->0의 역할\n",
    "\n",
    "    W = pres_w + delta\n",
    "    cost_p = Cost()\n",
    "    W = pres_w - delta\n",
    "    cost_m = Cost()\n",
    "    grad_w = (cost_p-cost_m)/(2*delta)\n",
    "    W = pres_w # w restore\n",
    "\n",
    "    B = pres_b + delta\n",
    "    cost_p = Cost()\n",
    "    B = pres_b - delta\n",
    "    cost_m = Cost()\n",
    "    grad_b = (cost_p-cost_m)/(2*delta)\n",
    "\n",
    "    B = pres_b # b restore\n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접 적어봄\n",
    "# def Gradient(x,y):\n",
    "#     return np.mean(x(W*x +(B-y))), np.mean(W*x +(B-y))\n",
    "\n",
    "\n",
    "# def Gradient(x,y):\n",
    "#     global W, B\n",
    "#     prev_W = W; prev_B = B\n",
    "#     delta = 5e-7\n",
    "\n",
    "#     W = prev_W + delta\n",
    "#     cost_plus = Cost()\n",
    "#     W = prev_W - delta\n",
    "#     cost_minus = Cost()\n",
    "#     grad_w = (cost_plus - cost_minus) / (2*delta)\n",
    "#     W = prev_W\n",
    "\n",
    "#     B = prev_B + delta\n",
    "#     cost_plus = Cost()\n",
    "#     B = prev_B - delta\n",
    "#     cost_minus = Cost()\n",
    "#     grad_b = (cost_plus - cost_minus) / (2*delta)\n",
    "#     B = prev_B\n",
    "\n",
    "#     return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Training\n",
    ">### $\\mu$ : Learning rate\n",
    ">### $w = w - \\mu\\frac{\\partial}{\\partial w}cost(w, b)$\n",
    ">### $b = b - \\mu\\frac{\\partial}{\\partial b}cost(w, b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient(x,y):\n",
    "    return np.mean(x*(W*x +(B-y))), np.mean(W*x +(B-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0] cost =  2.254e-08, W = 00002.0, B =  0.9997\n",
      "[   25] cost =  2.133e-08, W = 00002.0, B =  0.9997\n",
      "[   50] cost =  2.029e-08, W = 00002.0, B =  0.9997\n",
      "[   75] cost =  1.921e-08, W = 00002.0, B =  0.9997\n",
      "[  100] cost =  1.825e-08, W = 00002.0, B =  0.9997\n",
      "[  125] cost =  1.732e-08, W = 00002.0, B =  0.9997\n",
      "[  150] cost =  1.646e-08, W = 00002.0, B =  0.9997\n",
      "[  175] cost =  1.565e-08, W = 00002.0, B =  0.9997\n",
      "[  200] cost =  1.481e-08, W = 00002.0, B =  0.9997\n",
      "[  225] cost =  1.403e-08, W = 00002.0, B =  0.9997\n",
      "[  250] cost =  1.331e-08, W = 00002.0, B =  0.9998\n",
      "[  275] cost =  1.264e-08, W = 00002.0, B =  0.9998\n",
      "[  300] cost =  1.201e-08, W = 00002.0, B =  0.9998\n",
      "[  325] cost =  1.138e-08, W = 00002.0, B =  0.9998\n",
      "[  350] cost =  1.078e-08, W = 00002.0, B =  0.9998\n",
      "[  375] cost =  1.018e-08, W = 00002.0, B =  0.9998\n",
      "[  400] cost =  9.692e-09, W = 00002.0, B =  0.9998\n",
      "[  425] cost =  9.198e-09, W = 00002.0, B =  0.9998\n",
      "[  450] cost =  8.744e-09, W = 00002.0, B =  0.9998\n",
      "[  475] cost =  8.322e-09, W = 00002.0, B =  0.9998\n",
      "[  500] cost =  7.866e-09, W = 00002.0, B =  0.9998\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parameter Set\n",
    "epochs = 500\n",
    "learning_rate = 0.005\n",
    "\n",
    "# 학습 (Training)\n",
    "for cnt in range(0, epochs+1):\n",
    "    if cnt % (epochs//20) == 0:\n",
    "        print(\"[{0[0]:>5}] cost = {0[1]:>10.4}, W = {1[0]:0>7.4}, B = {1[1]:>7.4}\".format([cnt, Cost()], [W, B]))\n",
    "\n",
    "    #갱신하는 부분\n",
    "    grad_w, grad_b = Gradient(x_input, labels)\n",
    "    W -= learning_rate * grad_w\n",
    "    B -= learning_rate * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]  cost = 0.00000, W = 2.00003, B = 0.99981\n",
      "[20]  cost = 0.00000, W = 2.00003, B = 0.99982\n",
      "[40]  cost = 0.00000, W = 2.00003, B = 0.99982\n",
      "[60]  cost = 0.00000, W = 2.00002, B = 0.99983\n",
      "[80]  cost = 0.00000, W = 2.00002, B = 0.99984\n",
      "[100]  cost = 0.00000, W = 2.00002, B = 0.99984\n",
      "[120]  cost = 0.00000, W = 2.00002, B = 0.99985\n",
      "[140]  cost = 0.00000, W = 2.00002, B = 0.99986\n",
      "[160]  cost = 0.00000, W = 2.00002, B = 0.99986\n",
      "[180]  cost = 0.00000, W = 2.00002, B = 0.99987\n",
      "[200]  cost = 0.00000, W = 2.00002, B = 0.99987\n",
      "[220]  cost = 0.00000, W = 2.00002, B = 0.99988\n",
      "[240]  cost = 0.00000, W = 2.00002, B = 0.99988\n",
      "[260]  cost = 0.00000, W = 2.00002, B = 0.99989\n",
      "[280]  cost = 0.00000, W = 2.00002, B = 0.99989\n",
      "[300]  cost = 0.00000, W = 2.00001, B = 0.99990\n",
      "[320]  cost = 0.00000, W = 2.00001, B = 0.99990\n",
      "[340]  cost = 0.00000, W = 2.00001, B = 0.99991\n",
      "[360]  cost = 0.00000, W = 2.00001, B = 0.99991\n",
      "[380]  cost = 0.00000, W = 2.00001, B = 0.99991\n",
      "[400]  cost = 0.00000, W = 2.00001, B = 0.99992\n",
      "[420]  cost = 0.00000, W = 2.00001, B = 0.99992\n",
      "[440]  cost = 0.00000, W = 2.00001, B = 0.99992\n",
      "[460]  cost = 0.00000, W = 2.00001, B = 0.99993\n",
      "[480]  cost = 0.00000, W = 2.00001, B = 0.99993\n",
      "[500]  cost = 0.00000, W = 2.00001, B = 0.99993\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.0000096173300874, 0.9999331893981257)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "for cnt in range(0,epochs+1):\n",
    "    if cnt%20 == 0:\n",
    "        print(f\"[{cnt}]  cost = {Cost():.5f}, W = {W:.5f}, B = {B:.5f}\")\n",
    "    \n",
    "    grad_w, grad_b = Gradient(x_input,labels)\n",
    "    W -= (grad_w)*learning_rate\n",
    "    B -= (grad_b)*learning_rate\n",
    "\n",
    "W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
